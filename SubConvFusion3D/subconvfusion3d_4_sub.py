# -*- coding: utf-8 -*-
"""SubConvFusion3d 4 Sub.ipynb

Automatically generated by Colab.

"""

import patoolib
link = "/content/drive/MyDrive/DataSets/ModelNet40_sampled.rar"
patoolib.extract_archive(link)

def load_h5(h5_filename):
    f = h5py.File(h5_filename)
    data = f['data'][:]
    label = f['label'][:]
    return (data, label)

import numpy as np
import os
import h5py
#import np_utils
#from keras.utils import np_utils
#from keras.utils.np_utils import to_categorical
from keras.utils import to_categorical

path_to_data = "/content/ModelNet40_sampled"
num_points = 2048
k = 40

# load train points and labels
train_path = os.path.join(path_to_data, "PrepData")
filenames = [d for d in os.listdir(train_path)]
train_points = None
train_labels = None
for d in filenames:
    cur_points, cur_labels = load_h5(os.path.join(train_path, d))
    cur_points = cur_points.reshape(1, -1, 3)
    cur_labels = cur_labels.reshape(1, -1)
    if train_labels is None or train_points is None:
        train_labels = cur_labels
        train_points = cur_points
    else:
        train_labels = np.hstack((train_labels, cur_labels))
        train_points = np.hstack((train_points, cur_points))
train_points_r = train_points.reshape(-1, num_points, 3)
train_labels_r = train_labels.reshape(-1, 1)
# load test points and labels
test_path = os.path.join(path_to_data, "PrepData_test")
filenames = [d for d in os.listdir(test_path)]


# load Test points and labels
test_points = None
test_labels = None
for d in filenames:
    cur_points, cur_labels = load_h5(os.path.join(test_path, d))
    cur_points = cur_points.reshape(1, -1, 3)
    cur_labels = cur_labels.reshape(1, -1)
    if test_labels is None or test_points is None:
        test_labels = cur_labels
        test_points = cur_points
    else:
        test_labels = np.hstack((test_labels, cur_labels))
        test_points = np.hstack((test_points, cur_points))
test_points_r = test_points.reshape(-1, num_points, 3)
test_labels_r = test_labels.reshape(-1, 1)

#
# label to categorical
Y_train = to_categorical(train_labels_r, k)
Y_test = to_categorical(test_labels_r, k)

print(train_points_r.shape)
print(test_points_r.shape)
print(Y_train.shape)
print(Y_test.shape)

from keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Input, BatchNormalization, Dense
from keras.layers import Reshape, Lambda, concatenate ,Conv1DTranspose ,Permute
from keras.models import Model
from keras.layers import Layer

#from keras.engine.topology import Layer
import numpy as np
#from keras.utils import np_utils
import tensorflow as tf

class MatMul(Layer):

    def __init__(self, **kwargs):
        super(MatMul, self).__init__(**kwargs)

    def build(self, input_shape):
        # Used purely for shape validation.
        if not isinstance(input_shape, list):
            raise ValueError('`MatMul` layer should be called '
                             'on a list of inputs')
        if len(input_shape) != 2:
            raise ValueError('The input of `MatMul` layer should be a list containing 2 elements')

        if len(input_shape[0]) != 3 or len(input_shape[1]) != 3:
            raise ValueError('The dimensions of each element of inputs should be 3')

        if input_shape[0][-1] != input_shape[1][1]:
            raise ValueError(f"The last dimension of inputs[0] :{input_shape} should match the dimension 1 of inputs[1] {input_shape[1][1]}")

    def call(self, inputs):
        if not isinstance(inputs, list):
            raise ValueError('A `MatMul` layer should be called '
                             'on a list of inputs.')
        return tf.matmul(inputs[0], inputs[1])

    def compute_output_shape(self, input_shape):
        output_shape = [input_shape[0][0], input_shape[0][1], input_shape[1][-1]]
        return tuple(output_shape)

from google.colab import drive
drive.mount('/content/drive')

def backEmptyNet(nb_classes =40):
    input_points = Input(shape=(2048, 3))

    # N 1
    x = Conv1D(64, 1, activation='relu')(input_points)
    x = BatchNormalization()(x)
    x = Conv1D(128, 1, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv1D(256, 1, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv1D(512, 1, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv1D(1024, 1, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv1D(1024, 1, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Permute((2,1))(x)
    x = MatMul()([x, input_points])
    x = Permute((2,1))(x)
    x = MaxPooling1D(pool_size=3)(x)
    x = BatchNormalization()(x)
    x = Permute((2,1))(x)

    # N 2
    y = Conv1D(64, 1, activation='relu')(input_points)
    y = BatchNormalization()(y)
    y = Conv1D(128, 1, activation='relu')(y)
    y = BatchNormalization()(y)
    y = Conv1D(256, 1, activation='relu')(y)
    y = BatchNormalization()(y)
    y = Conv1D(512, 1, activation='relu')(y)
    y = BatchNormalization()(y)
    y = Conv1D(1024, 1, activation='relu')(y)
    y = BatchNormalization()(y)
    y = Conv1D(512, 1, activation='relu')(y)
    y = BatchNormalization()(y)
    y = Permute((2,1))(y)
    y = MatMul()([y, input_points])
    y = Permute((2,1))(y)
    y = BatchNormalization()(y)
    y = MaxPooling1D(pool_size=3)(y)

    # N 3
    a = Conv1D(64, 1, activation='relu')(input_points)
    a = BatchNormalization()(a)
    a = Conv1D(128, 1, activation='relu')(a)
    a = BatchNormalization()(a)
    a = Conv1D(256, 1, activation='relu')(a)
    a = BatchNormalization()(a)
    a = Conv1D(512, 1, activation='relu')(a)
    a = BatchNormalization()(a)
    a = Conv1D(1024, 1, activation='relu')(a)
    a = BatchNormalization()(a)
    a = Conv1D(256, 1, activation='relu')(a)
    a = BatchNormalization()(a)
    a = Permute((2,1))(a)
    a = MatMul()([a, input_points])
    a = Permute((2,1))(a)
    a = BatchNormalization()(a)
    a = MaxPooling1D(pool_size=3)(a)

    # N 4
    z = Conv1D(64, 1, activation='relu')(input_points)
    z = BatchNormalization()(z)
    z = Conv1D(128, 1, activation='relu')(z)
    z = BatchNormalization()(z)
    z = Conv1D(256, 1, activation='relu')(z)
    z = BatchNormalization()(z)
    z = Conv1D(512, 1, activation='relu')(z)
    z = BatchNormalization()(z)
    z = Conv1D(1024, 1, activation='relu')(z)
    z = BatchNormalization()(z)
    z = Conv1D(128, 1, activation='relu')(z)
    z = BatchNormalization()(z)
    z = Permute((2,1))(z)
    z = MatMul()([z, input_points])
    z = Permute((2,1))(z)
    z = MaxPooling1D(pool_size=3)(z)
    z = BatchNormalization()(z)
   # z = Permute((2,1))(z)

    # calc
    m = MatMul()([x, y])
    m = BatchNormalization()(m)
    m = Permute((2,1))(m)
    m = MaxPooling1D(pool_size=512)(m)
    m = Permute((2,1))(m)
    m = MatMul()([m, a])
    m = BatchNormalization()(m)
    m = Permute((2,1))(m)
    m = MaxPooling1D(pool_size=256)(m)
    m = Permute((2,1))(m)
    m = MatMul()([m, z])
    m = BatchNormalization()(m)
    m = Permute((2,1))(m)
    m = MaxPooling1D(pool_size=128)(m)


    c = Dense(512, activation='relu')(m)
    c = BatchNormalization()(c)
    c = Dropout(0.5)(c)
    c = Dense(256, activation='relu')(c)
    c = BatchNormalization()(c)
    c = Dropout(0.5)(c)
    c = Dense(nb_classes, activation='softmax')(c)
    prediction = Flatten()(c)

    model = Model(inputs=input_points, outputs=prediction)
    model.compile(optimizer='adam' ,loss="mse", metrics=['accuracy'])
    return model

path= "/content/drive/My Drive/back_network50.h5"
model = backEmptyNet()
print(model.summary())


his =  model.fit(train_points_r, Y_train,validation_split=0.33 , batch_size=32, epochs=50, verbose=1)

score = model.evaluate(test_points_r, Y_test, verbose=1)
print('Test loss: ', score[0])
print('Test accuracy: ', score[1])

#merge dataset
all_data = np.concatenate((train_points_r ,test_points_r) , axis =0)
all_labels = np.concatenate((Y_train ,Y_test) , axis =0)
print(all_data.shape)
print(all_labels.shape)


score = model.evaluate(all_data,all_labels, verbose=1)
print('Test loss: ', score[0])
print('Test accuracy: ', score[1])

path= "/content/drive/My Drive/back_network100.h5"
# serialize weights to HDF5
model.save_weights(path)
print("Saved model to disk")
